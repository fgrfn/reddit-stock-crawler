# ğŸ“ˆ Reddit Stock Crawler (r/wallstreetbets)

This tool helps you **easily and quickly identify which stocks are currently trending** on the r/wallstreetbets subreddit.

It scans Reddit posts and comments for ticker mentions (e.g. `NVDA`, `$TSLA`) from the past 24 hours, aggregates the results, and presents them in a **color-coded Excel dashboard** â€“ making it simple to spot hyped or rising stocks before the news hits.

---

## ğŸš€ Features

- ğŸ§  Scans latest Reddit posts + comments (past 24h)
- ğŸ” Detects mentions of US stock tickers (e.g. `GOOG`, `$AAPL`)
- âš ï¸ Ignores false positives via configurable blacklist
- ğŸ“ Stores results as Pickle files with timestamps
- ğŸ“Š Generates a **color-coded Excel sheet** showing ticker trends over time
- âš™ï¸ Fully automatable via cronjobs or scheduled scripts

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/youruser/reddit-stock-crawler.git
cd reddit-stock-crawler
chmod +x install_reddit_crawler.sh
./install_reddit_crawler.sh
```

The installer will:
- Prompt for an installation path and Reddit API credentials
- Create a virtual Python environment (`venv`)
- Install all required dependencies
- Set up the base scripts and launcher

---

## ğŸ” Requirements

### âœ… Reddit API Access

1. Go to [Reddit Apps](https://www.reddit.com/prefs/apps)
2. Click **Create App**, choose **Script**
3. Use `http://localhost:8080` as redirect URI
4. Note down:
   - **Client ID**
   - **Client Secret**
   - **User Agent** (e.g. `python:reddit-crawler:v1.0 (by /u/yourusername)`)

---

## ğŸ“¦ Dependencies

Installed automatically into a virtual environment:

- `praw` â€“ Reddit API wrapper
- `pandas` â€“ data processing
- `openpyxl` â€“ Excel writing
- `python-dotenv` â€“ for loading `.env` credentials

---

## ğŸ§ª Usage

Run the full crawler + Excel update:

```bash
./run_reddit_crawler.sh
```

This will:
1. Search for ticker mentions in the last 100 posts/comments on r/wallstreetbets
2. Store results in `./pickle/<timestamp>_crawler-ergebnis.pkl`
3. Update your Excel report (`crawler_results_aktuell.xlsx`)

To enable Excel output, download the formatting template:

```bash
wget https://www.heise.de/downloads/18/4/8/7/4/3/8/6/crawler_results-vorlage.xlsx
```

Place the file in your project root.

---

## ğŸ“Š Output Files

- `symbols_list.pkl` â†’ list of tickers to track
- `pickle/*.pkl` â†’ daily result files with counts
- `crawler_results_aktuell.xlsx` â†’ full overview in Excel, color-coded (green = trending)

---

## ğŸ•’ Automation

You can run the crawler daily using a cronjob:

```bash
0 7 * * * /path/to/project/run_reddit_crawler.sh >> /path/to/project/logs/cron.log 2>&1
```

---

## ğŸ¯ Why Use This?

This script is ideal for:

- Retail traders and investors who want **early signals** on trending stocks
- Content creators and analysts monitoring Reddit-driven market moves
- Anyone who wants to **track WSB hype without reading 1,000+ comments**

---

## ğŸ“Œ Roadmap Ideas

- ğŸŸ¡ Sentiment analysis (bullish / bearish comments)
- ğŸ§¹ Auto-cleanup for inactive tickers
- ğŸŒ Web dashboard or API backend
- ğŸ“‰ Long-term trend visualization

---

## ğŸ“„ License

MIT License

---

## ğŸ™Œ Credits

- Based on this [Heise Online article](https://www.heise.de/ratgeber/Reddit-Crawler-fuer-Aktien-in-Python-bauen-So-geht-es-Schritt-fuer-Schritt-10442095.html)
- Extended and scripted for automation & ease-of-use
